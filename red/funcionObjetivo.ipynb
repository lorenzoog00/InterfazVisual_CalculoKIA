{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables de entrada\n",
    "x1, x2, x3, x4, x5, x6 = sp.symbols('x1 x2 x3 x4 x5 x6')\n",
    "x = sp.Matrix([x1, x2, x3, x4, x5, x6])\n",
    "\n",
    "# Definir pesos y sesgos como variables simbólicas\n",
    "W1 = sp.MatrixSymbol('W1', 6, 872)\n",
    "b1 = sp.MatrixSymbol('b1', 872, 1)\n",
    "W2 = sp.MatrixSymbol('W2', 872, 864)\n",
    "b2 = sp.MatrixSymbol('b2', 864, 1)\n",
    "W3 = sp.MatrixSymbol('W3', 864, 1)\n",
    "b3 = sp.MatrixSymbol('b3', 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir funciones de activación simbólicas\n",
    "def relu(x):\n",
    "    return sp.Piecewise((0, x <= 0), (x, x > 0))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + sp.exp(-x))\n",
    "\n",
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagación hacia adelante simbólica\n",
    "z1 = W1.T * x + b1\n",
    "a1 = z1.applyfunc(relu)\n",
    "\n",
    "z2 = W2.T * a1 + b2\n",
    "a2 = z2.applyfunc(sigmoid)\n",
    "\n",
    "z3 = W3.T * a2 + b3\n",
    "output = linear(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle b_{3} + W_{3}^{T} {\\left( d \\mapsto \\frac{1}{1 + e^{- d}} \\right)}_{\\circ}\\left({b_{2} + W_{2}^{T} {\\left( d \\mapsto \\begin{cases} 0 & \\text{for}\\: d \\leq 0 \\\\d & \\text{otherwise} \\end{cases} \\right)}_{\\circ}\\left({b_{1} + W_{1}^{T} \\left[\\begin{matrix}x_{1}\\\\x_{2}\\\\x_{3}\\\\x_{4}\\\\x_{5}\\\\x_{6}\\end{matrix}\\right]}\\right)}\\right)$"
      ],
      "text/plain": [
       "b3 + W3.T*Lambda(_d, 1/(1 + exp(-_d))).(b2 + W2.T*Lambda(_d, Piecewise((0, _d <= 0), (_d, True))).(b1 + W1.T*Matrix([\n",
       "[x1],\n",
       "[x2],\n",
       "[x3],\n",
       "[x4],\n",
       "[x5],\n",
       "[x6]])))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar la función de salida simbólica\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediciendo salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "c:\\Users\\PcR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.4.0 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo y definir la función neural_network_function como antes\n",
    "model = load_model('../best_model_2.4367305027108534e-05.h5')\n",
    "# Cargar los escaladores\n",
    "scaler_X = joblib.load('../minmax_scaler_X.pkl')\n",
    "scaler_y = joblib.load('../minmax_scaler_y.pkl')\n",
    "\n",
    "W1, b1 = model.layers[0].get_weights()\n",
    "W2, b2 = model.layers[1].get_weights()\n",
    "W3, b3 = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def neural_network_function(input_data):\n",
    "    z1 = np.dot(input_data, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    return z3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar el Excel con las predicciones\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../matriz_datos_con_predicciones.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m scaler_X\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mX\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extraer las columnas de entrada y la columna de predicciones\u001b[39;00m\n\u001b[0;32m      6\u001b[0m input_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt_mea\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_gas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL_\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Cargar el Excel con las predicciones\n",
    "df = pd.read_excel('../matriz_datos_con_predicciones.xlsx')\n",
    "X_normalized = scaler_X.transform(X)\n",
    "\n",
    "# Extraer las columnas de entrada y la columna de predicciones\n",
    "input_columns = ['y1', 'G_', 'wt_mea', 'z', 'T_gas', 'L_']\n",
    "X = df[input_columns].values\n",
    "y_pred_original = df['Kg RED'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PcR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Normalizar los datos de entrada\n",
    "X_normalized = scaler_X.transform(X)\n",
    "\n",
    "# Aplicar la función neural_network_function a los datos normalizados\n",
    "y_pred_new_normalized = np.array([neural_network_function(x.reshape(1, -1)) for x in X_normalized])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación:\n",
    "En el código, estamos comparando tres conjuntos de predicciones:\n",
    "\n",
    "Las predicciones originales que ya estaban en tu archivo Excel.\n",
    "Las nuevas predicciones hechas con nuestra función neural_network_function.\n",
    "Las predicciones hechas directamente con el modelo cargado de Keras/TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio entre las predicciones originales y las nuevas: 5.947353057765384e-08\n"
     ]
    }
   ],
   "source": [
    "# Desnormalizar las predicciones\n",
    "y_pred_new = scaler_y.inverse_transform(y_pred_new_normalized.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "mse = np.mean((y_pred_original - y_pred_new)**2)\n",
    "print(f\"Error cuadrático medio entre las predicciones originales y las nuevas: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación de predicciones:\n",
      "Original: 0.000383, Nueva: 0.000293, Diferencia: 0.000090\n",
      "Original: 0.000383, Nueva: 0.000293, Diferencia: 0.000090\n",
      "Original: 0.000383, Nueva: 0.000293, Diferencia: 0.000090\n",
      "Original: 0.000383, Nueva: 0.000292, Diferencia: 0.000091\n",
      "Original: 0.000383, Nueva: 0.000293, Diferencia: 0.000091\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Comparar algunas predicciones individuales\n",
    "print(\"\\nComparación de predicciones:\")\n",
    "for i in range(min(5, len(y_pred_original))):\n",
    "    print(f\"Original: {y_pred_original[i]:.6f}, Nueva: {y_pred_new[i]:.6f}, Diferencia: {abs(y_pred_original[i] - y_pred_new[i]):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "# Usar el modelo de Keras directamente para comparar\n",
    "y_pred_keras = model.predict(X_normalized)\n",
    "y_pred_keras = scaler_y.inverse_transform(y_pred_keras).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación con predicciones de Keras:\n",
      "Original: 0.000383, Keras: 0.000383, Nueva: 0.000293\n",
      "Original: 0.000383, Keras: 0.000383, Nueva: 0.000293\n",
      "Original: 0.000383, Keras: 0.000383, Nueva: 0.000293\n",
      "Original: 0.000383, Keras: 0.000383, Nueva: 0.000292\n",
      "Original: 0.000383, Keras: 0.000383, Nueva: 0.000293\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparación con predicciones de Keras:\")\n",
    "for i in range(min(5, len(y_pred_original))):\n",
    "    print(f\"Original: {y_pred_original[i]:.6f}, Keras: {y_pred_keras[i]:.6f}, Nueva: {y_pred_new[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error cuadrático medio entre las predicciones originales y Keras: 1.2351208758639977e-39\n"
     ]
    }
   ],
   "source": [
    "# Calcular el error cuadrático medio con las predicciones de Keras\n",
    "mse_keras = np.mean((y_pred_original - y_pred_keras)**2)\n",
    "print(f\"\\nError cuadrático medio entre las predicciones originales y Keras: {mse_keras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
